{
  "student_id": "137507",
  "student_name": "Shon DeCamp",
  "entries": [
    {
      "author": "Shon DeCamp",
      "post_date": "2025-05-07T09:01:04-06:00",
      "content": "I found the mention of both ethnographic and quantitative data intriguing.\nAs a product manager I worked on a software product which coordinated employee schedules with forecasted demand and labor regulations. For one project, I began by interviewing users and also observing their interactions with the software in a contextual inquiry. The outcomes of this analysis suggested that helping users find ideal shifts would be the best area of focus. The quantitative analysis of user behavior yielded significantly different results. Using Splunk and some custom tracking software I was able to visualize user pathways through the application. There was a massive pattern of users repeatedly viewing a particular list, completing an associated form, and starting over again. It became clear that although finding ideal shifts would impact business goals, changing the design for the list, form, repeat experience would have a much more significant impact on system load, user time on task, and other key metrics. I went back and interviewed users about this list, form, repeat experience and learned more critical details about how to design.\nThis and other similar experiences has taught me that quantitative data analysis can help narrow the focus, while ethnographic or observational analysis helps expound on critical areas.\nHave any of you found the opposite to be true? Have you seen ethnographic and observation analysis as a more effective method for selecting an area of focus?"
    },
    {
      "author": "Shon DeCamp",
      "post_date": "2025-05-08T17:57:16-06:00",
      "content": "I understand your point about the tendency to delay decisions in pursuit of perfect data. I think this is where risk analysis has become a significant aspect of project management. It's certainly tempting to seek more comprehensive information, but as you mentioned, this can lead to \"analysis paralysis\" and hinder project progress. \nEstablishing clear data requirements and a defined timeline for data collection and analysis could be a useful strategy to mitigate this issue. This approach would encourage a balance between thoroughness and the need for timely decision-making, preventing projects from becoming stalled indefinitely. One point that stood out from the lectures as our readings this week was step 3 in the Universal Approach to Measurement: \"Compute the value of additional information (if none, make a decision).\" At a certain point in any project a threshold is crossed where either (a) the value of additional information gained by launching, implementing, etc. is greater than the value of information gained through analysis or (b) further analysis is possible but holds little or no value.\nI've always been a fan of setting a time and resource budget in my R&D work. Setting that budget based on project estimations brings a lot of alignment and efficiency for a team and project."
    }
  ],
  "status": "Successfully extracted 2 entries for student 137507. (from iframe)",
  "error": null
}